{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurent Neural Network V1 Test 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Travail effectué\n",
    "* RNN avec 3 couches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from Fonctions_utils import f1_m, matrix_confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"../../data_models/df_train.csv\")\n",
    "df_val = pd.read_csv(\"../../data_models/df_val.csv\")\n",
    "df_test = pd.read_csv(\"../../data_models/df_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_train = df_train[\"text_clean\"].values.astype(str)\n",
    "sentences_val = df_val[\"text_clean\"].values.astype(str)\n",
    "sentences_test = df_test[\"text_clean\"].values.astype(str)\n",
    "\n",
    "y_train = df_train[\"Insult\"].values\n",
    "y_val = df_val[\"Insult\"].values\n",
    "y_test = df_test[\"Insult\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(sentences_train)\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(sentences_train)\n",
    "X_val = tokenizer.texts_to_sequences(sentences_val)\n",
    "X_test = tokenizer.texts_to_sequences(sentences_test)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The indexing is ordered after the most common words in the text, which you can see by the word the having the index 1. It is important to note that the index 0 is reserved and is not assigned to any word. This zero index is used for padding, which I’ll introduce in a moment"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One problem that we have is that each text sequence has in most cases different length of words. To counter this, you can use pad_sequence() which simply pads the sequence of words with zeros. By default, it prepends zeros but we want to append them. Typically it does not matter whether you prepend or append zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 100\n",
    "\n",
    "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
    "X_val = pad_sequences(X_val, padding='post', maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 50\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Embedding(input_dim=vocab_size, \n",
    "                           output_dim=embedding_dim, \n",
    "                           input_length=maxlen))\n",
    "model.add(layers.LSTM(units=32, activation='tanh'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "# compile the model\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=[f1_m, 'accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2762 samples, validate on 1185 samples\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-28 20:16:20.528884: W tensorflow/core/grappler/optimizers/implementation_selector.cc:310] Skipping optimization due to error while loading function libraries: Invalid argument: Functions '__inference___backward_standard_lstm_69536_70021_specialized_for_StatefulPartitionedCall_at___inference_distributed_function_70205' and '__inference___backward_cudnn_lstm_with_fallback_69203_69385' both implement 'lstm_82fae96b-c331-4f6d-808e-434ace2a9fa2' but their signatures do not match.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2760/2762 [============================>.] - ETA: 0s - loss: 0.5846 - accuracy: 0.7348"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-28 20:17:11.658053: W tensorflow/core/grappler/optimizers/implementation_selector.cc:310] Skipping optimization due to error while loading function libraries: Invalid argument: Functions '__inference_standard_lstm_71236_specialized_for_sequential_3_lstm_2_StatefulPartitionedCall_at___inference_distributed_function_71595' and '__inference_cudnn_lstm_with_fallback_71347' both implement 'lstm_59359fcd-741d-4dde-b95d-c9d529ec3f7e' but their signatures do not match.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2762/2762 [==============================] - 58s 21ms/sample - loss: 0.5844 - accuracy: 0.7350 - val_loss: 0.5930 - val_accuracy: 0.7325\n",
      "Epoch 2/50\n",
      "2762/2762 [==============================] - 52s 19ms/sample - loss: 0.5809 - accuracy: 0.7350 - val_loss: 0.5847 - val_accuracy: 0.7325\n",
      "Epoch 3/50\n",
      "2762/2762 [==============================] - 53s 19ms/sample - loss: 0.5802 - accuracy: 0.7350 - val_loss: 0.5914 - val_accuracy: 0.7325\n",
      "Epoch 4/50\n",
      "2762/2762 [==============================] - 53s 19ms/sample - loss: 0.5796 - accuracy: 0.7350 - val_loss: 0.5809 - val_accuracy: 0.7325\n",
      "Epoch 5/50\n",
      "2762/2762 [==============================] - 54s 20ms/sample - loss: 0.5810 - accuracy: 0.7350 - val_loss: 0.5814 - val_accuracy: 0.7325\n",
      "Epoch 6/50\n",
      "2762/2762 [==============================] - 52s 19ms/sample - loss: 0.5800 - accuracy: 0.7350 - val_loss: 0.5810 - val_accuracy: 0.7325\n",
      "Epoch 7/50\n",
      "2762/2762 [==============================] - 52s 19ms/sample - loss: 0.5793 - accuracy: 0.7350 - val_loss: 0.5804 - val_accuracy: 0.7325\n",
      "Epoch 8/50\n",
      "2762/2762 [==============================] - 52s 19ms/sample - loss: 0.5797 - accuracy: 0.7350 - val_loss: 0.5800 - val_accuracy: 0.7325\n",
      "Epoch 9/50\n",
      "2762/2762 [==============================] - 51s 19ms/sample - loss: 0.5789 - accuracy: 0.7350 - val_loss: 0.5797 - val_accuracy: 0.7325\n",
      "Epoch 10/50\n",
      "2762/2762 [==============================] - 53s 19ms/sample - loss: 0.5773 - accuracy: 0.7350 - val_loss: 0.5829 - val_accuracy: 0.7325\n",
      "Epoch 11/50\n",
      "2762/2762 [==============================] - 53s 19ms/sample - loss: 0.5781 - accuracy: 0.7350 - val_loss: 0.5796 - val_accuracy: 0.7325\n",
      "Epoch 12/50\n",
      "2762/2762 [==============================] - 53s 19ms/sample - loss: 0.5771 - accuracy: 0.7350 - val_loss: 0.5800 - val_accuracy: 0.7325\n",
      "Epoch 13/50\n",
      "2762/2762 [==============================] - 181s 65ms/sample - loss: 0.5763 - accuracy: 0.7350 - val_loss: 0.5809 - val_accuracy: 0.7325\n",
      "Epoch 14/50\n",
      "1460/2762 [==============>...............] - ETA: 22s - loss: 0.5788 - accuracy: 0.7342"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mLe Kernel s’est bloqué lors de l’exécution du code dans la cellule active ou une cellule précédente. Veuillez vérifier le code dans la ou les cellules pour identifier une cause possible de l’échec. Cliquez <a href='https://aka.ms/vscodeJupyterKernelCrash'>ici</a> pour plus d’informations. Pour plus d’informations, consultez Jupyter <a href='command:jupyter.viewOutput'>log</a>."
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=30,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    verbose=2,\n",
    "                    batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "\n",
    "def plot_history(history):\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    x = range(1, len(acc) + 1)\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(x, acc, 'b', label='Training acc')\n",
    "    plt.plot(x, val_acc, 'r', label='Validation acc')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.legend()\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(x, loss, 'b', label='Training loss')\n",
    "    plt.plot(x, val_loss, 'r', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_test = model.predict(X_test)\n",
    "y_predict_test2 = [round(item) for sublist in y_predict_test.tolist() for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_confusion(y_test, y_predict_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = ['Neutre', 'Insultant']\n",
    "print(classification_report(y_test, y_predict_test2, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
