{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"../data_models/df_train.csv\")\n",
    "df_test = pd.read_csv(\"../data_models/df_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train[\"text_clean\"]\n",
    "X_test = df_test[\"text_clean\"]\n",
    "\n",
    "y_train = df_train[\"Insult\"].values\n",
    "y_test = df_test[\"Insult\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mLe Kernel s’est bloqué lors de l’exécution du code dans la cellule active ou une cellule précédente. Veuillez vérifier le code dans la ou les cellules pour identifier une cause possible de l’échec. Cliquez <a href='https://aka.ms/vscodeJupyterKernelCrash'>ici</a> pour plus d’informations. Pour plus d’informations, consultez Jupyter <a href='command:jupyter.viewOutput'>log</a>."
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing import text, sequence\n",
    "import numpy as np\n",
    "from keras.layers import Conv1D, Input, Embedding, MaxPooling1D, Dense, GlobalMaxPooling1D, SpatialDropout1D, Dropout, Flatten,LSTM\n",
    "from keras import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_index = {}\n",
    "for i, line in enumerate(open('wiki-news-300d-1M.vec')):\n",
    "    values = line.split()\n",
    "    embeddings_index[values[0]] = np.asarray(values[1:], dtype='float32')\n",
    "\n",
    "# create a tokenizer \n",
    "token = text.Tokenizer()\n",
    "token.fit_on_texts(X_train)\n",
    "word_index = token.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create token-embedding mapping\n",
    "embedding_matrix = np.zeros((len(word_index) + 1, 300))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       if someone were to write a parody of a it woul...\n",
       "1       very sorry about robin however i can guarantee...\n",
       "2          damn vince you shit dont ever go right for you\n",
       "3       you are a asshole for putting addicts down why...\n",
       "4       think if a little man like pac makes floyd run...\n",
       "                              ...                        \n",
       "2639    there is no way roger maywheather said these t...\n",
       "2640    iain duncan smith is clearly a dangerous socio...\n",
       "2641    no fucking way you ca leave us ca you knock ov...\n",
       "2642    you an idiot we should be sued for all the shi...\n",
       "2643    shut the fuck up so where do you shop your clo...\n",
       "Name: text_clean, Length: 2644, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_words = 16684\n",
    "MAX_SEQUENCE_LENGTH=70\n",
    "text_input_layer = Input(shape=(70,) ,dtype='int32')\n",
    "embedding_layer = Embedding(max_words, 300, weights=[embedding_matrix],input_length=MAX_SEQUENCE_LENGTH,\n",
    "                                trainable=True)(text_input_layer)\n",
    "text_layer = Conv1D(256, 3, activation='relu')(embedding_layer)\n",
    "text_layer = Dropout(0.3)(text_layer)\n",
    "text_layer = MaxPooling1D(3)(text_layer)\n",
    "text_layer = Conv1D(256, 3, activation='relu')(text_layer)\n",
    "text_layer = Dropout(0.3)(text_layer)\n",
    "text_layer = MaxPooling1D(3)(text_layer)\n",
    "text_layer = Conv1D(256, 3, activation='relu')(text_layer)\n",
    "text_layer = Dropout(0.3)(text_layer)\n",
    "text_layer = MaxPooling1D(3)(text_layer)\n",
    "text_layer = GlobalMaxPooling1D()(text_layer)\n",
    "text_layer = Dense(256, activation='relu')(text_layer)\n",
    "output_layer = Dense(1, activation='sigmoid')(text_layer)\n",
    "model = Model(text_input_layer, output_layer)\n",
    "model.summary()\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
